{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manipulate paths\n",
    "import os\n",
    "\n",
    "#Audio utilities libraries\n",
    "from scipy.io import wavfile as wav\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "import IPython.display as ipd\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "\n",
    "#plot libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#tree load\n",
    "import joblib\n",
    "\n",
    "#keras for predictions\n",
    "import keras\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento modello per il rilevamento di volti frontali\n",
    "face_detector = cv.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet = keras.models.load_model('FaceRecognition.h5')\n",
    "recnet = keras.models.load_model('FFNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Lorenzo' ,'Raffaele', 'Riprova']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img):\n",
    "    \n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    face = img\n",
    "    \n",
    "    faces = face_detector.detectMultiScale(gray, minSize=(250,250), minNeighbors=10)\n",
    "     \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        face = img[y:y+h,x:x+w]\n",
    "\n",
    "        img_pixels = cv.resize(face, (224, 224)) \n",
    "        img_pixels = img_to_array(img_pixels)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels = preprocess_input(img_pixels)\n",
    "        y_prob = facenet.predict(img_pixels)\n",
    "        y_pred = np.argmax(y_prob)\n",
    "        y_prob = y_prob[0, y_pred]\n",
    "\n",
    "        if(y_prob > 0.85):\n",
    "            index = names[y_pred]\n",
    "        else:\n",
    "            index = \"Unknown\"\n",
    "\n",
    "        cv.putText(img,\n",
    "                  (str(index)+''+str(y_prob)),\n",
    "                  (x+5,y-5),\n",
    "                  cv.FONT_HERSHEY_SIMPLEX,\n",
    "                  1,\n",
    "                  (255,255,255),\n",
    "                  2)\n",
    "                    \n",
    "    return img, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "duration = 2 # (qqqsecondi)\n",
    "rec_rate = 44100\n",
    "sent='Press \"r\" to register'\n",
    "cv.startWindowThread()\n",
    "\n",
    "while(True):\n",
    "    color = (255,0,0)\n",
    "    r, frame = cap.read()\n",
    "    frame, faces = process_frame(frame)\n",
    "    cv.putText(frame, sent, (15, 37), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)  \n",
    "    cv.rectangle(frame, (1, 1), (850, 45), (255,255,255), 2)\n",
    "    cv.imshow('Video', frame)\n",
    "    \n",
    "    if cv.waitKey(20) & 0xFF == ord('r'):\n",
    "        prova = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "        wav.write('test.wav', rate=rec_rate, data=(prova))\n",
    "        rec_rate, rec = wav.read('test.wav')\n",
    "        mfcc = np.mean(librosa.feature.mfcc(rec*1.0, sr=int(rec_rate), n_mfcc=20).T, axis=0)\n",
    "        mfcc = mfcc.reshape(1,mfcc.shape[0])\n",
    "        prob_audio = recnet.predict(mfcc)\n",
    "        \n",
    "        if max(prob_audio[0]) < 0.6: \n",
    "            pred_audio = 4 \n",
    "        else:   \n",
    "            pred_audio = np.argmax(prob_audio)\n",
    "\n",
    "        if   pred_audio==0:\n",
    "            res = \"Raffaele ha detto acconsento\"\n",
    "\n",
    "        elif pred_audio == 1:\n",
    "            res =\"Raffaele ha detto rifiuto\"\n",
    "\n",
    "        elif pred_audio == 2:\n",
    "            res =\"Lorenzo ha detto acconsento\"\n",
    "\n",
    "        elif pred_audio == 3:\n",
    "            res =\"Lorenzo ha detto rifiuto\"\n",
    "\n",
    "        else:\n",
    "            res =\"Retry\"\n",
    "\n",
    "        sent = str(res)+''+str(prob_audio[0][pred_audio])\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
